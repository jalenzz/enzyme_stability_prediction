{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiLayerTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size=1280 * 3):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def create_dataset(features, labels, batch_size=32):\n",
    "    dataset = torch.utils.data.TensorDataset(features, labels)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, train_loader, loss_fn, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = loss_fn(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 960]) torch.Size([1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jalen/code/enzyme_stability_prediction/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/jalen/code/enzyme_stability_prediction/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Average Loss: 1405.2165\n",
      "Epoch 10, Average Loss: 237.7694\n",
      "Epoch 20, Average Loss: 218.2690\n",
      "Epoch 30, Average Loss: 236.2615\n",
      "Epoch 40, Average Loss: 231.2914\n",
      "Epoch 50, Average Loss: 217.1115\n",
      "Epoch 60, Average Loss: 210.2934\n",
      "Epoch 70, Average Loss: 245.4939\n",
      "Epoch 80, Average Loss: 213.8843\n",
      "Epoch 90, Average Loss: 201.7368\n"
     ]
    }
   ],
   "source": [
    "# Load the features and labels\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../data/train_features_1000.csv\")\n",
    "train_label = train_data[\"tm\"].values\n",
    "train_features = train_data[\"features\"].values\n",
    "train_features = [eval(i) for i in train_features]\n",
    "\n",
    "train_features = torch.tensor(train_features, dtype=torch.float32)\n",
    "train_label = torch.tensor(train_label, dtype=torch.float32)\n",
    "\n",
    "print(train_features.shape, train_label.shape)\n",
    "\n",
    "train_loader = create_dataset(train_features, train_label)\n",
    "\n",
    "# Create the model\n",
    "model = MultiLayerTMPredictor(input_size=480*2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "train_model(model, optimizer, train_loader, loss_fn, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression CV MSE: -11788.2109\n",
      "Ridge Regression CV MSE: -137.5139\n",
      "Random Forest CV MSE: -72.0502\n",
      "Gradient Boosting CV MSE: -74.7600\n",
      "Support Vector Regression CV MSE: -108.2614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jalen/code/enzyme_stability_prediction/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jalen/code/enzyme_stability_prediction/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jalen/code/enzyme_stability_prediction/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network CV MSE: -118.7773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jalen/code/enzyme_stability_prediction/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "\n",
    "# 加载特征和标签数据\n",
    "train_data = pd.read_csv(\"../data/train_features_1000.csv\")\n",
    "train_label = train_data[\"tm\"].values\n",
    "train_features = train_data[\"features\"].values\n",
    "train_features = [eval(i) for i in train_features]\n",
    "\n",
    "train_features = torch.tensor(train_features, dtype=torch.float32)\n",
    "train_label = torch.tensor(train_label, dtype=torch.float32)\n",
    "y = pd.read_csv(\"../data/train.csv\")[\"tm\"].values\n",
    "\n",
    "# 定义模型\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Regression\": SVR(kernel=\"rbf\", C=1.0, epsilon=0.1)\n",
    "}\n",
    "\n",
    "# val\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, train_features, train_label, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    print(f\"{name} CV MSE: {scores.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
